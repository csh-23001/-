# 1 lora微调LLama2
## 1 lora微调是什么？
  Alpaca-Lora 是利用 Lora 技术，在冻结原模型 LLaMA 参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。
  由于这些新增参数数量较少，这样不仅微调的成本显著下降，还能获得和全模型微调（full fine-tuning）类似的效果。
  LoRA 的最大优势是速度更快，使用的内存更少；因此，可以在消费级硬件上运行。
## 2 用lora微调LLama2，实际微调过程中的心得体会，难点是什么？
- 模型和tokenizer的载入：需要确保正确载入预训练模型权重和tokenizer。在国内网络环境下，可能需要手动下载模型权重到本地，或者处理权限问题以获取权重。
- 数据准备：微调数据集通常需要包含指令、输入和输出三个部分。构建这样的数据集需要精确地定义任务描述和相应的输入输出样例。
- 模型训练和保存：训练过程中可能需要设置额外的参数或实现特定功能，这要求对训练环境和任务有深入了解。此外，量化操作和设备映射也是微调时需要考虑的技术细节。
- 超参数选择：如秩、Alpha值和目标模块的选择对模型质量和serving效率有重大影响。需要在效率和模型质量之间做出权衡，这通常取决于具体任务。
- 训练稳定性：使用LoRA时，可能需要通过智能提示技术来稳定训练，采用较低的学习率可以增强模型检查点的可靠性。
# 如果想要在某个大语言模型上做全参数微调，需要多少显存
进行大型语言模型的全参数微调所需的显存量取决于多个因素，包括模型的大小、批处理大小（Batch Size）、序列长度，以及是否采用了显存优化技术。一般来说，全参数微调所需的显存是推理所需显存的3-4倍。
例如，ChatGLM-6B这样的模型，在FP16半精度下需要至少13GB的显存进行推理。如果结合模型量化技术，这一需求可以进一步降低到10GB（INT8）和6GB（INT4）2。而全参数微调所需的显存约为推理所需显存的10倍左右，也就是模型参数的20倍左右。
具体到不同的模型和配置，这里有一些经验数值：
16 bits全参数微调：7B模型需要160GB，13B模型需要320GB，30B模型需要600GB，65B模型需要1200GB。
4 bits的QLoRA微调：7B模型需要6GB，13B模型需要12GB，30B模型需要24GB，65B模型需要48GB。
这些数据仅供参考，实际所需显存可能会因具体情况而有所不同。如果您有具体的模型和配置需求，可以提供更多信息，以便获得更准确的估计。

# 什么是SFT指令微调？
SFT指令微调，即有监督微调（Supervised Fine-Tuning），是一种在大型语言模型（LLMs）上进行的微调过程。这个过程使用标记数据对预训练模型进行调整，以便模型能够更好地执行特定任务。
在有监督微调中，模型会根据提供的指令和相应的输出数据进行训练，从而提高其理解指令和生成正确回答的能力。这种方法通常用于提升模型在特定领域内的表现，例如客服对话、专业知识问答等场景。
简单来说，SFT指令微调就是通过精确的训练数据集，使得模型能够更准确地理解和执行用户的指令。这些训练数据集通常包含了大量的指令和对应的回答，以帮助模型学习如何处理各种不同的任务。
## 为什么SFT之后感觉大语言模型变傻了？
SFT之后，如果感觉大语言模型的表现变差了，可能有几个原因。
- 首先，SFT过程中可能会出现不稳定性，这可能是由于训练数据的波动、模型的随机性，或者是混合精度训练带来的问题。例如，如果在训练过程中使用了不同的数据批次或者模型参数设置，即使是相同的数据，模型的预测结果也可能会有所不同。
- 其次，SFT可能导致模型在特定任务上过度优化，从而影响其在其他任务上的表现。这种情况通常发生在模型被微调以执行特定类型的任务时，可能会丧失一些通用性。
- 还有一个可能的原因是，SFT过程中使用的数据可能不够多样化或者不够代表性，导致模型在实际应用中的表现不佳。如果训练数据集中的示例太少或者太特定，模型可能无法很好地泛化到新的、未见过的数据上3。
总的来说，SFT是一个复杂的过程，需要仔细平衡各种因素，以确保模型在微调后能够保持良好的性能和泛化能力。如果在SFT之后感觉模型的表现有所下降，可能需要重新审视训练数据、模型设置和训练策略。
## 进行STF操作的时候，基座模型选chat还是base？
在进行STF（有监督微调）操作时，选择chat模型还是base模型主要取决于你的数据量和特定的业务需求。
如果你的数据量较小（例如少于10k），建议使用chat模型作为基座进行微调。因为chat模型已经经过了对话任务的优化，所以在数据量不足以进行大规模微调的情况下，它可能会提供更好的性能1。
另一方面，如果你拥有较大的数据集（例如超过100k），那么在base模型上进行微调可能会更合适。base模型具有更强的泛化能力，可以更好地适应你的领域数据，尤其是当你的领域数据与预训练数据集差异较大时2。
此外，如果你追求领域任务的效果，并且希望通用能力不下降，建议选择base模型作为基座模型。在base模型上进行多任务混合训练时，需要关注各任务间的数据配比1。
## 指令微调有什么好处？
指令微调的好处主要包括：
- 提高模型的可控性和预测性：通过指令微调，模型可以更准确地遵循用户的指令，产生与指令相匹配的输出。这使得模型的行为更可控，输出更可预测。
- 弥合训练目标与用户目标之间的差距：传统的大型语言模型通常通过预测下一个词来进行训练，而用户希望模型能够有效且安全地遵循他们的指令。指令微调通过在由指令和输出对组成的数据集上进一步训练模型，缩小了这两者之间的差异。
- 提高计算效率：相比于从头开始训练一个全新的模型，指令微调只需要在已有的大型语言模型基础上进行，因此可以节省大量的计算资源和时间。
增强模型的泛化能力：指令微调可以帮助模型更好地适应特定领域的数据和任务，从而提高其在新任务和领域中的表现。
- 优化算法执行效率：在机器学习中，指令微调可以优化算法的执行效率，使得算法在处理大量数据时能够更快地得出结果，这对于需要快速响应的应用场景尤为重要。
