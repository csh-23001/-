# 1 lora微调LLama2
## 1 lora微调是什么？
  Alpaca-Lora 是利用 Lora 技术，在冻结原模型 LLaMA 参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。
  由于这些新增参数数量较少，这样不仅微调的成本显著下降，还能获得和全模型微调（full fine-tuning）类似的效果。
  LoRA 的最大优势是速度更快，使用的内存更少；因此，可以在消费级硬件上运行。
## 2 用lora微调LLama2，实际微调过程中的心得体会，难点是什么？
- 模型和tokenizer的载入：需要确保正确载入预训练模型权重和tokenizer。在国内网络环境下，可能需要手动下载模型权重到本地，或者处理权限问题以获取权重。
- 数据准备：微调数据集通常需要包含指令、输入和输出三个部分。构建这样的数据集需要精确地定义任务描述和相应的输入输出样例。
- 模型训练和保存：训练过程中可能需要设置额外的参数或实现特定功能，这要求对训练环境和任务有深入了解。此外，量化操作和设备映射也是微调时需要考虑的技术细节。
- 超参数选择：如秩、Alpha值和目标模块的选择对模型质量和serving效率有重大影响。需要在效率和模型质量之间做出权衡，这通常取决于具体任务。
- 训练稳定性：使用LoRA时，可能需要通过智能提示技术来稳定训练，采用较低的学习率可以增强模型检查点的可靠性。
