# 1 lora微调LLama2
## 1 lora微调是什么？
  Alpaca-Lora 是利用 Lora 技术，在冻结原模型 LLaMA 参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。
  由于这些新增参数数量较少，这样不仅微调的成本显著下降，还能获得和全模型微调（full fine-tuning）类似的效果。
  LoRA 的最大优势是速度更快，使用的内存更少；因此，可以在消费级硬件上运行。
## 2 用lora微调LLama2，实际微调过程中的心得体会，难点是什么？
- 模型和tokenizer的载入：需要确保正确载入预训练模型权重和tokenizer。在国内网络环境下，可能需要手动下载模型权重到本地，或者处理权限问题以获取权重。
- 数据准备：微调数据集通常需要包含指令、输入和输出三个部分。构建这样的数据集需要精确地定义任务描述和相应的输入输出样例。
- 模型训练和保存：训练过程中可能需要设置额外的参数或实现特定功能，这要求对训练环境和任务有深入了解。此外，量化操作和设备映射也是微调时需要考虑的技术细节。
- 超参数选择：如秩、Alpha值和目标模块的选择对模型质量和serving效率有重大影响。需要在效率和模型质量之间做出权衡，这通常取决于具体任务。
- 训练稳定性：使用LoRA时，可能需要通过智能提示技术来稳定训练，采用较低的学习率可以增强模型检查点的可靠性。
# 如果想要在某个大语言模型上做全参数微调，需要多少显存
进行大型语言模型的全参数微调所需的显存量取决于多个因素，包括模型的大小、批处理大小（Batch Size）、序列长度，以及是否采用了显存优化技术。一般来说，全参数微调所需的显存是推理所需显存的3-4倍。
例如，ChatGLM-6B这样的模型，在FP16半精度下需要至少13GB的显存进行推理。如果结合模型量化技术，这一需求可以进一步降低到10GB（INT8）和6GB（INT4）2。而全参数微调所需的显存约为推理所需显存的10倍左右，也就是模型参数的20倍左右。
具体到不同的模型和配置，这里有一些经验数值：
16 bits全参数微调：7B模型需要160GB，13B模型需要320GB，30B模型需要600GB，65B模型需要1200GB。
4 bits的QLoRA微调：7B模型需要6GB，13B模型需要12GB，30B模型需要24GB，65B模型需要48GB。
这些数据仅供参考，实际所需显存可能会因具体情况而有所不同。如果您有具体的模型和配置需求，可以提供更多信息，以便获得更准确的估计。

# 什么是SFT指令微调？
SFT指令微调，即有监督微调（Supervised Fine-Tuning），是一种在大型语言模型（LLMs）上进行的微调过程。这个过程使用标记数据对预训练模型进行调整，以便模型能够更好地执行特定任务。
在有监督微调中，模型会根据提供的指令和相应的输出数据进行训练，从而提高其理解指令和生成正确回答的能力。这种方法通常用于提升模型在特定领域内的表现，例如客服对话、专业知识问答等场景。
简单来说，SFT指令微调就是通过精确的训练数据集，使得模型能够更准确地理解和执行用户的指令。这些训练数据集通常包含了大量的指令和对应的回答，以帮助模型学习如何处理各种不同的任务。
## 为什么SFT之后感觉大语言模型变傻了？
SFT之后，如果感觉大语言模型的表现变差了，可能有几个原因。
- 首先，SFT过程中可能会出现不稳定性，这可能是由于训练数据的波动、模型的随机性，或者是混合精度训练带来的问题。例如，如果在训练过程中使用了不同的数据批次或者模型参数设置，即使是相同的数据，模型的预测结果也可能会有所不同。
- 其次，SFT可能导致模型在特定任务上过度优化，从而影响其在其他任务上的表现。这种情况通常发生在模型被微调以执行特定类型的任务时，可能会丧失一些通用性。
- 还有一个可能的原因是，SFT过程中使用的数据可能不够多样化或者不够代表性，导致模型在实际应用中的表现不佳。如果训练数据集中的示例太少或者太特定，模型可能无法很好地泛化到新的、未见过的数据上3。
总的来说，SFT是一个复杂的过程，需要仔细平衡各种因素，以确保模型在微调后能够保持良好的性能和泛化能力。如果在SFT之后感觉模型的表现有所下降，可能需要重新审视训练数据、模型设置和训练策略。
## 进行STF操作的时候，基座模型选chat还是base？
在进行STF（有监督微调）操作时，选择chat模型还是base模型主要取决于你的数据量和特定的业务需求。
如果你的数据量较小（例如少于10k），建议使用chat模型作为基座进行微调。因为chat模型已经经过了对话任务的优化，所以在数据量不足以进行大规模微调的情况下，它可能会提供更好的性能1。
另一方面，如果你拥有较大的数据集（例如超过100k），那么在base模型上进行微调可能会更合适。base模型具有更强的泛化能力，可以更好地适应你的领域数据，尤其是当你的领域数据与预训练数据集差异较大时2。
此外，如果你追求领域任务的效果，并且希望通用能力不下降，建议选择base模型作为基座模型。在base模型上进行多任务混合训练时，需要关注各任务间的数据配比1。
## 指令微调有什么好处？
指令微调的好处主要包括：
- 提高模型的可控性和预测性：通过指令微调，模型可以更准确地遵循用户的指令，产生与指令相匹配的输出。这使得模型的行为更可控，输出更可预测。
- 弥合训练目标与用户目标之间的差距：传统的大型语言模型通常通过预测下一个词来进行训练，而用户希望模型能够有效且安全地遵循他们的指令。指令微调通过在由指令和输出对组成的数据集上进一步训练模型，缩小了这两者之间的差异。
- 提高计算效率：相比于从头开始训练一个全新的模型，指令微调只需要在已有的大型语言模型基础上进行，因此可以节省大量的计算资源和时间。
增强模型的泛化能力：指令微调可以帮助模型更好地适应特定领域的数据和任务，从而提高其在新任务和领域中的表现。
- 优化算法执行效率：在机器学习中，指令微调可以优化算法的执行效率，使得算法在处理大量数据时能够更快地得出结果，这对于需要快速响应的应用场景尤为重要。

# 领域大模型的continue pretrain 的数据应该如何选取？
领域大模型的 Continue PreTrain 阶段的数据选取是非常重要的。让我为您总结一些关键点：
- 技术标准文档或领域相关数据：这些是领域模型 Continue PreTrain 的关键。您可以使用领域相关的网站、资讯，或者技术标准文档作为预训练数据。这些数据应该覆盖目标任务的各种情况，以便模型能够学习到足够的领域知识.
- 领域数据与通用数据的平衡：领域数据训练后，通用能力可能会下降。因此，建议混合通用数据以缓解模型遗忘通用能力。当数据量有限时，一般数据比例在1:5到1:10之间是比较合适的.
- SFT数据的加入：在领域模型 Continue PreTrain 时，可以同步加入 SFT数据，即 MIP（Multi-Task Instruction PreTraining）。这样可以让模型在预训练过程中就学习到更多的知识。
- 词表扩增：领域模型词表扩增是否有必要取决于具体情况。一般来说，领域词表扩增主要解决的是解码效率的问题，对模型效果的提升可能不会很大。
- 领域评测集：建议准备两份领域评测集，一份选择题形式自动评测，一份开放形式人工评测。这样可以进行初筛和精筛，并且任务形式更贴近真实场景。
# 领域数据训练后，通用能力往往会有所下降，如何缓解模型遗忘通用能力？
缓解模型在领域数据训练后遗忘通用能力的问题，可以采取以下几种策略：
- 保留通用数据：在进行领域数据训练时，保留一部分通用数据用于模型训练，确保模型能够继续学习到通用的语言和知识1。
- 增量学习：使用增量学习（Incremental Learning）的方法，将领域数据与通用数据逐步交替进行训练，这样可以在学习新领域的同时，保持对通用知识的记忆1。
- 数据重采样：在进行领域数据训练时，可以使用数据重采样的方法，使得模型在训练过程中能够更多地接触到通用数据，从而缓解遗忘通用能力的问题1。
- 强化学习：通过给模型设置奖励机制，鼓励模型在领域任务上表现好，同时保持一定的通用能力1。
- 领域适应技术：使用领域适应技术，如领域自适应（Domain Adaptation）和领域对抗训练（Domain Adversarial Training），帮助模型在不同领域之间进行迁移学习，从而减少遗忘通用能力的问题1。
- Replay：在训练数据中混合模型原有的训练数据和已有文本匹配数据，这种方法被称为Replay1。
- EWC (Elastic Weights Consolidation)：这是一种参数正则化方法，通过对模型参数施加约束，防止新模型参数偏离原模型太远，从而减少灾难性遗忘1。
# 领域模型Continue PreTrain，如何 让模型在预训练过程中就学习到更多的知识？
在领域模型的Continue PreTrain（持续预训练）过程中，让模型学习到更多知识的关键在于优化数据选择和训练策略。以下是一些有效的方法：
- 加入SFT数据：在预训练过程中加入SFT（Specific Fine-Tuning）数据，可以让模型学习到更多的领域特定知识。这种方法被称为MIP（Multi-Task Instruction PreTraining），可以在预训练阶段就让模型接触到多任务学习，从而提升其在特定领域的表现。
- 数据质量和覆盖率：选择高质量和高覆盖率的领域数据，如技术标准文档或领域相关书籍，这些数据通常信息密度大，能够帮助模型更好地理解和适应领域知识。
- 混合通用数据：为了防止模型在学习领域知识时遗忘通用知识，可以将领域数据与通用数据混合使用。这样做可以平衡模型在领域特定任务和通用任务上的能力。
- 评测集的使用：建议准备两份领域评测集，一份选择题形式自动评测，一份开放形式人工评测。这样可以在预训练过程中对模型进行有效的监督和调整。
- warmup策略：合理设置warmup步数，即学习率从一个较小的值逐渐增加到最大值的过程。这可以帮助模型在预训练初期更好地适应新数据，减少性能损伤1。
- 学习率调整：探究不同的学习率对模型学习效果的影响。一般来说，较大的学习率有助于模型在下游任务上的表现，但可能会导致上游任务的性能下降。因此，需要根据实际情况调整学习率。
# 领域模型微调 指令&数据输入格式 要求是什么？
输入数据格式：
- 输入数据通常是一个二维数组，每行代表一个样本，每列代表一个特征。
- 如果我们的输入数据是文本，那么每行可能是一个句子，每列可能是该句子的一个词。
目标数据格式：
- 目标数据通常是一个一维数组，每个元素对应输入数据的一行。
- 例如，如果我们的任务是文本分类，目标数据可能是一个包含类别标签的数组。
# 领域模型词表扩增是不是有必要的？
领域模型的词表扩增是一个值得考虑的问题。让我为您总结一下：
词表扩增的必要性：
- 词表扩增是指在自然语言处理任务中，通过添加新的词汇或短语，扩大模型的词汇资源库，从而提高模型的处理能力和泛化性能。
- 通过增加词汇量，模型可以更好地处理复杂和多样的输入数据。
实际应用中的考虑：
- 在实际应用中，开发者可以通过分析数据集的特点，针对性地扩充词表，从而提高模型的性能。
- 领域模型的词表扩增可以帮助模型更好地掌握领域内的语言规律，提高模型对未见过词汇和新语义的推断能力。
