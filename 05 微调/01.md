# 1 lora微调LLama2
## 1 lora微调是什么？
  Alpaca-Lora 是利用 Lora 技术，在冻结原模型 LLaMA 参数的情况下，通过往模型中加入额外的网络层，并只训练这些新增的网络层参数。
  由于这些新增参数数量较少，这样不仅微调的成本显著下降，还能获得和全模型微调（full fine-tuning）类似的效果。
  LoRA 的最大优势是速度更快，使用的内存更少；因此，可以在消费级硬件上运行。
## 2 用lora微调LLama2，实际微调过程中的心得体会，难点是什么？
- 模型和tokenizer的载入：需要确保正确载入预训练模型权重和tokenizer。在国内网络环境下，可能需要手动下载模型权重到本地，或者处理权限问题以获取权重。
- 数据准备：微调数据集通常需要包含指令、输入和输出三个部分。构建这样的数据集需要精确地定义任务描述和相应的输入输出样例。
- 模型训练和保存：训练过程中可能需要设置额外的参数或实现特定功能，这要求对训练环境和任务有深入了解。此外，量化操作和设备映射也是微调时需要考虑的技术细节。
- 超参数选择：如秩、Alpha值和目标模块的选择对模型质量和serving效率有重大影响。需要在效率和模型质量之间做出权衡，这通常取决于具体任务。
- 训练稳定性：使用LoRA时，可能需要通过智能提示技术来稳定训练，采用较低的学习率可以增强模型检查点的可靠性。
# 如果想要在某个大语言模型上做全参数微调，需要多少显存
进行大型语言模型的全参数微调所需的显存量取决于多个因素，包括模型的大小、批处理大小（Batch Size）、序列长度，以及是否采用了显存优化技术。一般来说，==全参数微调所需的显存是推理所需显存的3-4倍==。
例如，ChatGLM-6B这样的模型，在FP16半精度下需要至少13GB的显存进行推理。如果结合模型量化技术，这一需求可以进一步降低到10GB（INT8）和6GB（INT4）2。而全参数微调所需的显存约为推理所需显存的10倍左右，也就是模型参数的20倍左右。
具体到不同的模型和配置，这里有一些经验数值：
16 bits全参数微调：7B模型需要160GB，13B模型需要320GB，30B模型需要600GB，65B模型需要1200GB。
4 bits的QLoRA微调：7B模型需要6GB，13B模型需要12GB，30B模型需要24GB，65B模型需要48GB。
这些数据仅供参考，实际所需显存可能会因具体情况而有所不同。如果您有具体的模型和配置需求，可以提供更多信息，以便获得更准确的估计。
