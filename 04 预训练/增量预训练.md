# 什么是增量预训练？
增量预训练是一种训练策略，允许模型在已有的知识基础上不断学习和改进。
在QLoRA中，增量预训练意味着模型会在原始预训练数据的基础上，不断添加新的数据并重新进行训练。
这样可以不断提高模型的泛化能力，使其更好地适应各种任务。指令微调则是针对特定任务对模型进行微调的过程。

# 进行增量预训练，需要做哪些准备工作？
进行增量预训练需要做以下准备工作：
- 选取底座模型：根据项目需求和硬件基础，选择合适的底座模型及模型参数量的大小。常见的底座模型包括LLaMA、BLOOM、Falcon、CPM-bee、Aquila、Baichuan等12.
- 收集数据：收集大量的文本数据，包含各个领域。通常，预训练数据的大小都是TB级别的。你可以从互联网上获取数据，例如wudao的200GB数据集和the pile的1TB数据量12.
- 数据清洗：对收集到的数据进行清洗。这一步骤非常关键，因为数据的质量直接影响模型的性能。清洗数据时，可以去除广告、噪声和其他不相关的信息。

# 增量预训练所用的训练框架是什么？
选择训练框架主要取决于资源情况。以下是不同资源情况下的训练框架选择建议：
超大规模训练：如果有足够的资源进行超大规模训练，可以选用3D并行。例如，Megatron-Deepspeed拥有多个成功案例，用于炼制大规模模型，例如炼制LLaMA2.
少量节点训练：如果只有少量节点，可以考虑张量并行。请注意，张量并行只在具备nvlink环境时才会起到正向作用，但提升可能不会太明显。
少量卡训练：如果资源非常有限，显存不够，可以使用LoRA进行增量预训练。LoRA是一种适用于资源受限情况下的训练方法。

# 增量预训练的训练流程是什么样的？
以下是基于LLaMA模型的增量预训练的实现步骤：
初始化LLaMA模型：选择一个预训练的LLaMA模型作为初始模型。
添加新知识：根据具体任务和数据，逐步添加新的知识和技能，以扩展模型的表达能力。这些新知识可以通过标注数据或无监督学习等方式获得。
模型微调：使用标注数据或其他方式对模型进行微调，使其更好地适应新增的知识和任务。微调时可以使用优化算法如随机梯度下降（SGD）等来更新模型的参数。
